{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bengali.AI Competition - Data Preprocessing\n",
    "### Team MuchLearningSuchWow\n",
    "\n",
    "This notebook contains the code we used to preprocess the data for the \"convolutional model\" part of our experiment. The four `.parquet` training files from Kaggle contain a total of 200.840 training images with a resolution of 236 by 137 pixels, taking up a total of 4.78 gigabytes. The graphemes in these images are not centered.\n",
    "\n",
    "In this notebook, we transform these images to a size of 64 by 64 pixels, and we center the graphemes and normalize pixel values. This reduces the size of the data to 271 megabytes, so that all data can be loaded in at once (instead of one `.parquet` file at a time).\n",
    "\n",
    "The code for centering, reshaping and normalizing the data is based heavily on [this](https://www.kaggle.com/iafoss/image-preprocessing-128x128) kaggle kernel. Note that this notebook is not intended to run on kaggle; to run this code on kaggle, add \"/kaggle/\" in front of all filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "RESIZE_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\\bengaliai-cv19\\best_model_conv.hdf5\n",
      "input\\bengaliai-cv19\\class_map.csv\n",
      "input\\bengaliai-cv19\\sample_submission.csv\n",
      "input\\bengaliai-cv19\\test.csv\n",
      "input\\bengaliai-cv19\\test_image_data_0.parquet\n",
      "input\\bengaliai-cv19\\test_image_data_1.parquet\n",
      "input\\bengaliai-cv19\\test_image_data_2.parquet\n",
      "input\\bengaliai-cv19\\test_image_data_3.parquet\n",
      "input\\bengaliai-cv19\\train.csv\n",
      "input\\bengaliai-cv19\\train_image_data_0.parquet\n",
      "input\\bengaliai-cv19\\train_image_data_1.parquet\n",
      "input\\bengaliai-cv19\\train_image_data_2.parquet\n",
      "input\\bengaliai-cv19\\train_image_data_3.parquet\n",
      "input\\bengaliai-cv19\\train_image_data_preprocessed.parquet\n",
      "input\\bengaliai-cv19\\train_image_data_preprocessed_0.parquet\n",
      "input\\bengaliai-cv19\\train_image_data_preprocessed_1.parquet\n",
      "input\\bengaliai-cv19\\train_image_data_preprocessed_2.parquet\n",
      "input\\bengaliai-cv19\\train_image_data_preprocessed_3.parquet\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = [\"input/bengaliai-cv19/train_image_data_0.parquet\",\n",
    "                   \"input/bengaliai-cv19/train_image_data_1.parquet\",\n",
    "                   \"input/bengaliai-cv19/train_image_data_2.parquet\",\n",
    "                   \"input/bengaliai-cv19/train_image_data_3.parquet\"]\n",
    "processed_filenames = [\"input/bengaliai-cv19/train_image_data_preprocessed_0.parquet\",\n",
    "                       \"input/bengaliai-cv19/train_image_data_preprocessed_1.parquet\",\n",
    "                       \"input/bengaliai-cv19/train_image_data_preprocessed_2.parquet\",\n",
    "                       \"input/bengaliai-cv19/train_image_data_preprocessed_3.parquet\"]\n",
    "final_filename = \"input/bengaliai-cv19/train_image_data_preprocessed.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=RESIZE_SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    #remove lo intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    return cv2.resize(img,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222939b811694aa3a71e39bc81534f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a9f17f60334cd0b4dd775ab765c013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1393ead1266344a299acbb18477d5ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06b4dd86c4241359c17d12eaff0a0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For each training .parquet file:\n",
    "for i in range(len(train_filenames)):\n",
    "    # Load the dataframe and reshape it to the correct size\n",
    "    df = pd.read_parquet(train_filenames[i])\n",
    "    data = 255 - df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)\n",
    "    \n",
    "    # Process all images\n",
    "    processed = []\n",
    "    names = []\n",
    "    \n",
    "    for idx in tqdm(range(len(df))):\n",
    "        names.append(df.iloc[idx,0])\n",
    "        #normalize each image by its max val\n",
    "        img = (data[idx]*(255.0/data[idx].max())).astype(np.uint8)\n",
    "        img = crop_resize(img)\n",
    "        processed.append(img.flatten())\n",
    "    \n",
    "    # Delete the data to save memory\n",
    "    del df\n",
    "    del data\n",
    "    \n",
    "    # Convert the processed data to a dataframe\n",
    "    processed_df = pd.DataFrame(processed)\n",
    "    del processed\n",
    "\n",
    "    # Restore the \"image_id\" column\n",
    "    processed_df.insert(0, \"image_id\", names)\n",
    "    del names\n",
    "\n",
    "    # Convert the dataframe to a parquet table\n",
    "    table = pa.Table.from_pandas(processed_df)\n",
    "    del processed_df\n",
    "    \n",
    "    # Write the table to a parquet file\n",
    "    pq.write_table(table, processed_filenames[i])\n",
    "    del table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the separate preprocessed dataframes from the parquet files\n",
    "dfs = []\n",
    "for filename in processed_filenames:\n",
    "    dfs.append(pd.read_parquet(filename))\n",
    "\n",
    "# Combine all dataframes into a single dataframe\n",
    "combined_df = pd.concat(dfs)\n",
    "del dfs\n",
    "\n",
    "# Convert the combined dataframe to a parquet table\n",
    "table = pa.Table.from_pandas(combined_df)\n",
    "del combined_df\n",
    "\n",
    "# Write the table to a parquet file\n",
    "pq.write_table(table, final_filename)\n",
    "del table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (200840, 4097)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  0  1  2  3  4  5  6  7  8  ...  4086  4087  4088  4089  4090  \\\n",
       "0  Train_0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "1  Train_1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "2  Train_2  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "3  Train_3  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "4  Train_4  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "\n",
       "   4091  4092  4093  4094  4095  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 4097 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect whether preprocessing worked by re-loading the resulting dataframe from the parquet file\n",
    "df = pd.read_parquet(final_filename)\n",
    "print(\"Data shape: \"+str(df.shape))\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
