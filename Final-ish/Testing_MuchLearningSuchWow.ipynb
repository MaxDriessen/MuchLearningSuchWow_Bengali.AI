{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bengali.AI Competition - Model Testing\n",
    "\n",
    "### Team MuchLearningSuchWow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm.auto import tqdm\n",
    "import time, gc\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization,Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "IMG_SIZE = 64\n",
    "N_CHANNELS=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = [\"input/bengaliai-cv19/test_image_data_0.parquet\",\n",
    "                  \"input/bengaliai-cv19/test_image_data_1.parquet\",\n",
    "                  \"input/bengaliai-cv19/test_image_data_2.parquet\",\n",
    "                  \"input/bengaliai-cv19/test_image_data_3.parquet\"]\n",
    "model_filenames = [\"input/bengaliai-cv19/best_model_conv.hdf5\",\n",
    "                   \"input/bengaliai-cv19/best_model_conv.hdf5\",\n",
    "                   \"input/bengaliai-cv19/best_model_conv.hdf5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/iafoss/image-preprocessing-128x128\n",
    "\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=IMG_SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    #remove lo intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    return cv2.resize(img,(size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6edc48413fa457a8d04ff7cbf00052d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a352c41872448ba16aa937f19537e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ef9d899ec241d0b7e883c25b893095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0646459218a4a429e6f99ebcb9f7c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes = []\n",
    "\n",
    "# For each testing .parquet file:\n",
    "for i in range(len(test_filenames)):\n",
    "    # Load the dataframe and reshape it to the correct size\n",
    "    df = pd.read_parquet(test_filenames[i])\n",
    "    data = 255 - df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)\n",
    "    \n",
    "    # Process all images\n",
    "    processed = []\n",
    "    names = []\n",
    "    \n",
    "    for idx in tqdm(range(len(df))):\n",
    "        names.append(df.iloc[idx,0])\n",
    "        #normalize each image by its max val\n",
    "        img = (data[idx]*(255.0/data[idx].max())).astype(np.uint8)\n",
    "        img = crop_resize(img)\n",
    "        processed.append(img.flatten())\n",
    "    \n",
    "    # Delete the data to save memory\n",
    "    del df\n",
    "    del data\n",
    "    \n",
    "    # Convert the processed data to a dataframe\n",
    "    processed_df = pd.DataFrame(processed)\n",
    "    del processed\n",
    "\n",
    "    # Restore the \"image_id\" column\n",
    "    processed_df.insert(0, \"image_id\", names)\n",
    "    del names\n",
    "\n",
    "    dataframes.append(processed_df)\n",
    "\n",
    "test_df = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_convolutional():\n",
    "    inputs = Input(shape = (IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1))(inputs)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation = \"relu\")(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "    dense = Dense(512, activation = \"relu\")(model)\n",
    "\n",
    "    head_root = Dense(168, activation = 'softmax', name='dense_root')(dense)\n",
    "    head_vowel = Dense(11, activation = 'softmax', name='dense_vowel')(dense)\n",
    "    head_consonant = Dense(7, activation = 'softmax', name='dense_consonant')(dense)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], loss_weights=[0.5, 0.25, 0.25])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "conv_model1 = build_convolutional()\n",
    "conv_model1.load_weights(model_filenames[0])\n",
    "\n",
    "conv_model2 = build_convolutional()\n",
    "conv_model2.load_weights(model_filenames[0])\n",
    "\n",
    "conv_model3 = build_convolutional()\n",
    "conv_model3.load_weights(model_filenames[0])\n",
    "\n",
    "models.append(conv_model1)\n",
    "models.append(conv_model2)\n",
    "models.append(conv_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dict = {\n",
    "    'grapheme_root': [],\n",
    "    'vowel_diacritic': [],\n",
    "    'consonant_diacritic': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test_1_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       row_id  target\n",
       "0  Test_0_consonant_diacritic       4\n",
       "1        Test_0_grapheme_root     148\n",
       "2      Test_0_vowel_diacritic       9\n",
       "3  Test_1_consonant_diacritic       0\n",
       "4        Test_1_grapheme_root      32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n",
    "target=[] # model predictions placeholder\n",
    "row_id=[] # row_id place holder\n",
    "\n",
    "test_df.set_index('image_id', inplace=True)\n",
    "\n",
    "x_test = test_df.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n",
    "\n",
    "# Predict using all models\n",
    "preds = []\n",
    "for model in models:\n",
    "    prediction = model.predict(x_test)\n",
    "    if preds == []:\n",
    "        preds.extend(prediction)\n",
    "    else:\n",
    "        for d in range(len(preds)):\n",
    "            preds[d] = np.add(preds[d], prediction[d]) \n",
    "\n",
    "# Final prediction is class with the highest sum of predictions\n",
    "for i, p in enumerate(preds_dict):\n",
    "    preds_dict[p] = np.argmax(preds[i], axis=1)\n",
    "\n",
    "for k, id in enumerate(test_df.index.values):  \n",
    "    for i, comp in enumerate(components):\n",
    "        id_sample=id+'_'+comp\n",
    "        row_id.append(id_sample)\n",
    "        target.append(preds_dict[comp][k])\n",
    "\n",
    "del test_df\n",
    "del x_test\n",
    "gc.collect()\n",
    "\n",
    "df_sample = pd.DataFrame(\n",
    "    {\n",
    "        'row_id': row_id,\n",
    "        'target':target\n",
    "    },\n",
    "    columns = ['row_id','target'] \n",
    ")\n",
    "df_sample.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
