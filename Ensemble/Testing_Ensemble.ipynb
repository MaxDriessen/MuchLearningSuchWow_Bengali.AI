{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bengali.AI Competition - Model Testing (Ensemble)\n",
    "\n",
    "### Team MuchLearningSuchWow\n",
    "\n",
    "This notebook contains the code that we used to test our ensemble of networks that consists a CNN, ResNet, and two variations of ResNext. The resizing and tessting code in this notebook is based on [this kernel](https://www.kaggle.com/kaushal2896/bengali-graphemes-starter-eda-multi-output-cnn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.utils import generic_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filenames = ['output/model_resnext.h5', \n",
    "                   'output/model_cnn.h5', \n",
    "                   'output/model_resnet56.h5', \n",
    "                   'output/model_resnet38.h5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deserialize Keras Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_keras_object(identifier, module_objects=None, custom_objects=None, printable_module_name='object'):\n",
    "    if identifier is None:\n",
    "        return None\n",
    "    if isinstance(identifier, dict):\n",
    "        config = identifier\n",
    "        if 'class_name' not in config or 'config' not in config:\n",
    "            raise ValueError('Improper config format: ' + str(config))\n",
    "        class_name = config['class_name']\n",
    "        if custom_objects and class_name in custom_objects:\n",
    "            cls = custom_objects[class_name]\n",
    "        elif class_name in _GLOBAL_CUSTOM_OBJECTS:\n",
    "            cls = _GLOBAL_CUSTOM_OBJECTS[class_name]\n",
    "        else:\n",
    "            module_objects = module_objects or {}\n",
    "            cls = module_objects.get(class_name)\n",
    "            if cls is None:\n",
    "                from keras.metrics import Recall\n",
    "                cls = Recall\n",
    "        if hasattr(cls, 'from_config'):\n",
    "            custom_objects = custom_objects or {}\n",
    "            if has_arg(cls.from_config, 'custom_objects'):\n",
    "                return cls.from_config(\n",
    "                    config['config'],\n",
    "                    custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n",
    "                                        list(custom_objects.items())))\n",
    "            with CustomObjectScope(custom_objects):\n",
    "                return cls.from_config(config['config'])\n",
    "        else:\n",
    "            custom_objects = custom_objects or {}\n",
    "            with CustomObjectScope(custom_objects):\n",
    "                return cls(**config['config'])\n",
    "    elif isinstance(identifier, six.string_types):\n",
    "        function_name = identifier\n",
    "        if custom_objects and function_name in custom_objects:\n",
    "            fn = custom_objects.get(function_name)\n",
    "        elif function_name in _GLOBAL_CUSTOM_OBJECTS:\n",
    "            fn = _GLOBAL_CUSTOM_OBJECTS[function_name]\n",
    "        else:\n",
    "            fn = module_objects.get(function_name)\n",
    "            if fn is None:\n",
    "                raise ValueError('Unknown ' + printable_module_name +\n",
    "                                 ':' + function_name)\n",
    "        return fn\n",
    "    else:\n",
    "        raise ValueError('Could not interpret serialized ' +\n",
    "                         printable_module_name + ': ' + identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_utils.deserialize_keras_object.__code__ = deserialize_keras_object.__code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Resize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code obtained from: https://www.kaggle.com/kaushal2896/bengali-graphemes-starter-eda-multi-output-cnn\n",
    "def resize(df, size=64, need_progress_bar=True):\n",
    "    resized = {}\n",
    "    resize_size=64\n",
    "    if need_progress_bar:\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            image=df.loc[df.index[i]].values.reshape(137,236)\n",
    "            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "            idx = 0\n",
    "            ls_xmin = []\n",
    "            ls_ymin = []\n",
    "            ls_xmax = []\n",
    "            ls_ymax = []\n",
    "            for cnt in contours:\n",
    "                idx += 1\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                ls_xmin.append(x)\n",
    "                ls_ymin.append(y)\n",
    "                ls_xmax.append(x + w)\n",
    "                ls_ymax.append(y + h)\n",
    "            xmin = min(ls_xmin)\n",
    "            ymin = min(ls_ymin)\n",
    "            xmax = max(ls_xmax)\n",
    "            ymax = max(ls_ymax)\n",
    "\n",
    "            roi = image[ymin:ymax,xmin:xmax]\n",
    "            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n",
    "            resized[df.index[i]] = resized_roi.reshape(-1)\n",
    "    else:\n",
    "        for i in range(df.shape[0]):\n",
    "            image=df.loc[df.index[i]].values.reshape(137,236)\n",
    "            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "            idx = 0\n",
    "            ls_xmin = []\n",
    "            ls_ymin = []\n",
    "            ls_xmax = []\n",
    "            ls_ymax = []\n",
    "            for cnt in contours:\n",
    "                idx += 1\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                ls_xmin.append(x)\n",
    "                ls_ymin.append(y)\n",
    "                ls_xmax.append(x + w)\n",
    "                ls_ymax.append(y + h)\n",
    "            xmin = min(ls_xmin)\n",
    "            ymin = min(ls_ymin)\n",
    "            xmax = max(ls_xmax)\n",
    "            ymax = max(ls_ymax)\n",
    "\n",
    "            roi = image[ymin:ymax,xmin:xmax]\n",
    "            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n",
    "            resized[df.index[i]] = resized_roi.reshape(-1)\n",
    "    resized = pd.DataFrame(resized).T\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_a = joblib.load('../input/ensemble/clf_0')\n",
    "clf_b = joblib.load('../input/ensemble/clf_1')\n",
    "clf_c = joblib.load('../input/ensemble/clf_2')\n",
    "clfs = [clf_a, clf_b, clf_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = [168, 11, 7]\n",
    "\n",
    "image_ids = []\n",
    "image_preds = []\n",
    "\n",
    "components = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    test_df = pd.read_parquet(f'../input/bengaliai-cv19/test_image_data_{i}.parquet')\n",
    "    x_test = test_df.drop(['image_id'], axis=1)\n",
    "    x_test = resize(x_test) / 255\n",
    "\n",
    "    # CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n",
    "    x_test = x_test.values.reshape(-1, 64, 64, 1)\n",
    "\n",
    "    predictions = (\n",
    "        np.empty((len(x_test), 168 * len(model_filenames)), dtype=np.float32),\n",
    "        np.empty((len(x_test), 11 * len(model_filenames)), dtype=np.float32),\n",
    "        np.empty((len(x_test), 7 * len(model_filenames)), dtype=np.float32)\n",
    "    )\n",
    "\n",
    "    # Make model predictions     \n",
    "    for model_index, model_file in tqdm(enumerate(model_filenames), total=len(model_filenames)):\n",
    "        model = load_model(model_file)\n",
    "        preds = model.predict(x_test, batch_size=96)\n",
    "        for j in range(3):\n",
    "            predictions[j][:, model_index * n_classes[j]:(model_index + 1) * n_classes[j]] = preds[j]\n",
    "\n",
    "    ensemble_predictions = []\n",
    "\n",
    "    # Combine predicted scores using linear support vector machines\n",
    "    for j in range(3):\n",
    "        ensemble_predictions.append(clfs[j].predict(predictions[j]))\n",
    "\n",
    "    for k, id in enumerate(test_df['image_id']):\n",
    "        for j, comp in enumerate(components):\n",
    "            id_sample = id + '_' + comp\n",
    "            image_ids.append(id_sample)\n",
    "            image_preds.append(ensemble_predictions[j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.DataFrame(\n",
    "    {\n",
    "        'row_id': image_ids,\n",
    "        'target': image_preds\n",
    "    },\n",
    "    columns = ['row_id','target']\n",
    ")\n",
    "\n",
    "df_sample['target'] = df_sample['target'].astype(np.int)\n",
    "\n",
    "df_sample.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
