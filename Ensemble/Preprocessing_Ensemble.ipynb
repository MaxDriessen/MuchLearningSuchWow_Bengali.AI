{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bengali.AI Competition - Data Preprocessing (Ensemble)\n",
    "\n",
    "### Team MuchLearningSuchWow\n",
    "\n",
    "This notebook contains the code we used to preprocess the data for the \"ensemble\" part of our experiment. The preprocessing function was obtained from [this kernel](https://www.kaggle.com/kaushal2896/bengali-graphemes-starter-eda-multi-output-cnn). Note that this notebook is not intended to run on kaggle; to run this code on kaggle, add \"/kaggle/\" in front of all filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc\n",
    "import os\n",
    "import psutil\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"input/bengaliai-cv19/train.csv\"\n",
    "data_folder = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(df, size=64, need_progress_bar=True):\n",
    "    resized = {}\n",
    "    resize_size = 64\n",
    "    if need_progress_bar:\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            image = df.loc[df.index[i]].values.reshape(137, 236)\n",
    "            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "            idx = 0\n",
    "            ls_xmin = []\n",
    "            ls_ymin = []\n",
    "            ls_xmax = []\n",
    "            ls_ymax = []\n",
    "            for cnt in contours:\n",
    "                idx += 1\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                ls_xmin.append(x)\n",
    "                ls_ymin.append(y)\n",
    "                ls_xmax.append(x + w)\n",
    "                ls_ymax.append(y + h)\n",
    "            xmin = min(ls_xmin)\n",
    "            ymin = min(ls_ymin)\n",
    "            xmax = max(ls_xmax)\n",
    "            ymax = max(ls_ymax)\n",
    "\n",
    "            roi = image[ymin:ymax, xmin:xmax]\n",
    "            resized_roi = cv2.resize(roi, (resize_size, resize_size), interpolation=cv2.INTER_AREA)\n",
    "            resized[df.index[i]] = resized_roi.reshape(-1)\n",
    "    else:\n",
    "        for i in range(df.shape[0]):\n",
    "            image = df.loc[df.index[i]].values.reshape(137, 236)\n",
    "            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "            idx = 0\n",
    "            ls_xmin = []\n",
    "            ls_ymin = []\n",
    "            ls_xmax = []\n",
    "            ls_ymax = []\n",
    "            for cnt in contours:\n",
    "                idx += 1\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                ls_xmin.append(x)\n",
    "                ls_ymin.append(y)\n",
    "                ls_xmax.append(x + w)\n",
    "                ls_ymax.append(y + h)\n",
    "            xmin = min(ls_xmin)\n",
    "            ymin = min(ls_ymin)\n",
    "            xmax = max(ls_xmax)\n",
    "            ymax = max(ls_ymax)\n",
    "\n",
    "            roi = image[ymin:ymax, xmin:xmax]\n",
    "            resized_roi = cv2.resize(roi, (resize_size, resize_size), interpolation=cv2.INTER_AREA)\n",
    "            resized[df.index[i]] = resized_roi.reshape(-1)\n",
    "    resized = pd.DataFrame(resized).T\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ = pd.read_csv(train_filename)\n",
    "train_df_ = train_df_.drop(['grapheme'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(data_folder):\n",
    "    os.mkdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(4)):\n",
    "    train_df = pd.merge(pd.read_feather(f'train_image_data_{i}.feather'), train_df_, on='image_id', copy=False)\n",
    "    print(train_df.drop(['image_id', 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1).columns)\n",
    "    images = resize(train_df.drop(['image_id', 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1).astype(np.uint8))\n",
    "    images = images.values.reshape(-1, 64, 64)\n",
    "    gc.collect()\n",
    "\n",
    "    for j in tqdm(range(len(images))):\n",
    "        img = Image.fromarray(images[j])\n",
    "        img.save(f'data/{train_df[\"image_id\"].iloc[j]}.png')\n",
    "\n",
    "    gc.collect()\n",
    "    print(psutil.virtual_memory().percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
